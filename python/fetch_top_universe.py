import logging
from datetime import datetime, timedelta
from pathlib import Path

import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import sqlite3

DATA_DIR = Path("data")
UNIVERSE_CSV = DATA_DIR / "universe.csv"
SECTORS_CSV = DATA_DIR / "sectors.csv"
DB_PATH = DATA_DIR / "lee_trader.db"
try:
    from db import get_engine
except Exception:
    get_engine = None

# pykrx is required (added in requirements.txt)
try:
    from pykrx import stock
except Exception as e:
    stock = None

# FinanceDataReader for sector/industry metadata
try:
    import FinanceDataReader as fdr
except Exception:
    fdr = None


def setup_logging():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


def ensure_data_dir():
    DATA_DIR.mkdir(parents=True, exist_ok=True)


def last_trading_date(max_back_days: int = 10) -> str:
    """
    pykrxê°€ ë¹„ì˜ì—…ì¼ì´ê±°ë‚˜ ì¥ ì‹œì‘ ì „ì—ëŠ” 'ì‹œê°€ì´ì•¡=0'ì¸ DFë¥¼ ëŒë ¤ì¤„ ìˆ˜ ìˆì–´ì„œ,
    ì‹¤ì œë¡œ ì‹œê°€ì´ì•¡ ê°’ì´ ì¡´ì¬í•˜ëŠ” ë‚ ì§œë§Œ ê±°ë˜ì¼ë¡œ ì¸ì •í•œë‹¤.
    ë°˜í™˜ í˜•ì‹: YYYYMMDD
    """
    base = datetime.today()
    for i in range(max_back_days):
        dt = base - timedelta(days=i)
        ymd = dt.strftime("%Y%m%d")
        try:
            df = stock.get_market_cap_by_ticker(ymd, market="KOSPI")
            if df is None or df.empty:
                continue

            # ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ íƒìƒ‰ (top_by_marketì™€ ë™ì¼í•œ ë¡œì§ ì¼ë¶€ ì¬ì‚¬ìš©)
            mcap_col = None
            cols = list(df.columns)

            if "ì‹œê°€ì´ì•¡" in cols:
                mcap_col = "ì‹œê°€ì´ì•¡"
            else:
                for c in cols:
                    if "ì‹œê°€ì´" in str(c):
                        mcap_col = c
                        break

            if mcap_col is None:
                # numeric ì»¬ëŸ¼ ì¤‘ 'ìƒì¥ì£¼ì‹ìˆ˜'ëŠ” ì œì™¸í•˜ê³  ì‚¬ìš©
                num_cols = df.select_dtypes(include="number")
                num_cols = num_cols[[c for c in num_cols.columns if "ìƒì¥ì£¼" not in str(c)]]
                if not num_cols.empty:
                    mcap_col = num_cols.sum().idxmax()

            # ì‹œê°€ì´ì•¡ í›„ë³´ ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜, í•´ë‹¹ ì»¬ëŸ¼ì´ ì „ë¶€ 0ì´ë©´ ì´ ë‚ ì§œëŠ” íŒ¨ìŠ¤
            if mcap_col is None:
                continue

            mcap_series = df[mcap_col]
            # ìƒì¥ì£¼ì‹ìˆ˜ë§Œ ì‚´ì•„ìˆê³ , ë‹¤ë¥¸ ê°’ì´ ì „ë¶€ 0ì¸ ì¼€ì´ìŠ¤ë¥¼ í•„í„°ë§
            if (mcap_series.fillna(0) == 0).all():
                # logging.debug(f"{ymd}: mcap_col '{mcap_col}' is all zero, skip")
                continue

            # ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´ ìœ íš¨í•œ ê±°ë˜ì¼
            return ymd

        except Exception:
            continue

    # ì‹¤íŒ¨ ì‹œ ì˜¤ëŠ˜ ë‚ ì§œë¼ë„ ë°˜í™˜ (fallback)
    return base.strftime("%Y%m%d")



def top_by_market(ymd: str, market: str, top_n: int) -> pd.DataFrame:
    """
    market: 'KOSPI' or 'KOSDAQ'
    ë°˜í™˜: DataFrame with columns ['code', 'name', 'market']
    ì‹¤ì œ 'ì‹œê°€ì´ì•¡' ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ì¢…ëª©ë§Œ ë½‘ë„ë¡ ì»¬ëŸ¼ íƒìƒ‰ ë¡œì§ì„ ê°•í™”í–ˆë‹¤.
    """
    df = stock.get_market_cap_by_ticker(ymd, market=market)

    # ------------ DEBUG LOGS ------------
    if df is None or df.empty:
        logging.error(f"[DEBUG] {market} DataFrame is EMPTY")
    else:
        logging.info(f"[DEBUG] MARKET={market} RAW COLUMNS = {list(df.columns)}")
        logging.info(f"[DEBUG] MARKET={market} HEAD = \n{df.head(3)}")
    # ------------------------------------


    if df is None or df.empty:
        return pd.DataFrame(columns=["code", "name", "market"])

    mcap_col = None
    cols = list(df.columns)

    # 1) ì •í™•íˆ 'ì‹œê°€ì´ì•¡' ì´ë©´ ìµœìš°ì„ 
    if "ì‹œê°€ì´ì•¡" in cols:
        mcap_col = "ì‹œê°€ì´ì•¡"
    else:
        # 2) 'ì‹œê°€ì´' ì´ë¼ëŠ” ë¬¸ìì—´ì´ ë“¤ì–´ê°„ ì»¬ëŸ¼ (ì˜ˆ: 'ì‹œê°€ì´ì•¡(ë³´í†µì£¼)')
        for c in cols:
            if "ì‹œê°€ì´" in str(c):
                mcap_col = c
                break

        # 3) ì˜ë¬¸ cap ê´€ë ¨ ì»¬ëŸ¼ íƒìƒ‰ (mktcap, market_cap ë“±)
        if mcap_col is None:
            for c in cols:
                cl = str(c).lower()
                # 'mkt'ì™€ 'cap' ë‘˜ ë‹¤ ë“¤ì–´ê°€ëŠ” ê²½ìš°
                if "mkt" in cl and "cap" in cl:
                    mcap_col = c
                    break

        if mcap_col is None:
            for c in cols:
                cl = str(c).lower()
                # ë‹¨ìˆœíˆ cap ìœ¼ë¡œ ëë‚˜ëŠ” ìˆ«ìí˜• ì»¬ëŸ¼ (free cap ë“±ì€ ì œì™¸)
                if cl.endswith("cap") and "free" not in cl:
                    mcap_col = c
                    break

        # 4) ìµœí›„ì˜ ìˆ˜ë‹¨: ìˆ«ìí˜• ì»¬ëŸ¼ ì¤‘ í•©ê³„ê°€ ê°€ì¥ í° ì»¬ëŸ¼ì„ ì‹œì´ìœ¼ë¡œ ì¶”ì •
        if mcap_col is None:
            num_cols = df.select_dtypes(include="number")
            if not num_cols.empty:
                mcap_col = num_cols.sum().idxmax()

    # ğŸ”¥ ë°”ë¡œ ì—¬ê¸° ë„£ì–´ë¼! (ê°€ì¥ ì¤‘ìš”)
    logging.info(f"[DEBUG] MARKET={market} > USING MCAP COLUMN = {mcap_col}")
    
    if mcap_col is None:
        # ì§„ì§œë¡œ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì„ ëª» ì°¾ëŠ” ê²½ìš° â†’ ì¸ë±ìŠ¤ ìˆœì„œë¡œ fallback
        logging.warning(
            "[top_by_market] %s: ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. index ìˆœì„œ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ %dê°œ ì‚¬ìš©.",
            market,
            top_n,
        )
        codes = df.index.astype(str).str.zfill(6).tolist()[:top_n]
    else:
        # ì°¾ì€ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        logging.info(
            "[top_by_market] %s: ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ '%s' ì‚¬ìš©, ìƒìœ„ %dê°œ ì¶”ì¶œ",
            market,
            mcap_col,
            top_n,
        )
        df_sorted = df.sort_values(mcap_col, ascending=False)
        codes = df_sorted.index.astype(str).str.zfill(6).tolist()[:top_n]

    names = [stock.get_market_ticker_name(c) for c in codes]
    out = pd.DataFrame({"code": codes, "name": names})
    out["market"] = market
    return out



def main():
    setup_logging()
    ensure_data_dir()

    if stock is None:
        logging.error("pykrx is not installed. Please add 'pykrx' to requirements and rebuild the image.")
        return

    ymd = last_trading_date()
    logging.info(f"Using trading date: {ymd}")

    try:
        kospi_top = top_by_market(ymd, "KOSPI", top_n=100)
        logging.info(f"KOSPI top fetched: {len(kospi_top)}")
    except Exception as e:
        logging.exception(f"Failed to fetch KOSPI top: {e}")
        kospi_top = pd.DataFrame(columns=["code", "name"])

    try:
        kosdaq_top = top_by_market(ymd, "KOSDAQ", top_n=100)
        logging.info(f"KOSDAQ top fetched: {len(kosdaq_top)}")
    except Exception as e:
        logging.exception(f"Failed to fetch KOSDAQ top: {e}")
        kosdaq_top = pd.DataFrame(columns=["code", "name"])

    uni = pd.concat([kospi_top, kosdaq_top], ignore_index=True)
    # ì¤‘ë³µ ì œê±°, ì½”ë“œ ê¸°ì¤€ ìš°ì„  ìœ ì§€
    uni = uni.drop_duplicates(subset=["code"]).reset_index(drop=True)
    # ì»¬ëŸ¼ ì •ë¦¬ ë° ëŒ€ë¬¸ìí™”
    if "market" in uni.columns:
        uni["market"] = uni["market"].astype(str).str.upper().str.strip()
    else:
        uni["market"] = ""
    # ì´ì „ universe.csvì—ì„œ sector ë³´ì¡´ì„ ìœ„í•œ ë§µ êµ¬ì„±
    old_sector_map = {}
    try:
        if UNIVERSE_CSV.exists():
            old = pd.read_csv(UNIVERSE_CSV, dtype={"code": str})
            old["code"] = old["code"].astype(str).str.zfill(6)
            if "sector" in old.columns:
                old_sector_map = dict(zip(old["code"], old["sector"].fillna("").astype(str)))
    except Exception:
        pass

    # sector ë³‘í•©: data/sectors.csv(code, sector) ì¡´ì¬ ì‹œ left-merge
    if SECTORS_CSV.exists():
        try:
            s = pd.read_csv(SECTORS_CSV, dtype={"code": str})
            s["code"] = s["code"].astype(str).str.zfill(6)
            if "sector" in s.columns:
                uni = uni.merge(s[["code", "sector"]], on="code", how="left")
            else:
                uni["sector"] = ""
        except Exception:
            uni["sector"] = ""
    else:
        # sector ë¯¸ì œê³µ ì‹œ ê¸°ë³¸ê°’
        if "sector" not in uni.columns:
            uni["sector"] = ""
        else:
            uni["sector"] = uni["sector"].fillna("").astype(str)

    # FDR ë©”íƒ€ ë³‘í•©: ë¹„ì–´ìˆëŠ” sectorë¥¼ FDR(KRX/KOSPI/KOSDAQ) ë©”íƒ€ë¡œ ë³´ê°•
    if fdr is not None:
        try:
            metas = []
            for market_id in ["KRX", "KOSPI", "KOSDAQ"]:
                try:
                    m = fdr.StockListing(market_id)
                    if m is not None and not m.empty:
                        m["__market_id__"] = market_id
                        metas.append(m)
                except Exception:
                    continue
            if metas:
                meta = pd.concat(metas, ignore_index=True)
                # ì½”ë“œ ì»¬ëŸ¼ íƒì§€
                code_col = None
                for c in ["Code", "Symbol", "ì¢…ëª©ì½”ë“œ", "Ticker"]:
                    if c in meta.columns:
                        code_col = c
                        break
                # ì„¹í„°/ì‚°ì—… ì»¬ëŸ¼ í›„ë³´ íƒì§€
                sector_col = None
                # ìš°ì„ ìˆœìœ„: Sector, Industry, ì—…ì¢…, ì„¹í„°
                for c in meta.columns:
                    cl = str(c).lower()
                    if "sector" in cl or c in ["Sector"]:
                        sector_col = c
                        break
                if sector_col is None:
                    for c in meta.columns:
                        cl = str(c).lower()
                        if "industry" in cl or c in ["Industry", "ì—…ì¢…", "ì„¹í„°", "ì‚°ì—…"]:
                            sector_col = c
                            break
                if code_col and sector_col:
                    meta = meta[[code_col, sector_col]].rename(columns={code_col: "code", sector_col: "sector_fdr"})
                    meta["code"] = meta["code"].astype(str).str.zfill(6)
                    # merge í›„ ë¹ˆ sectorë§Œ FDR ê°’ìœ¼ë¡œ ì±„ì›€
                    uni = uni.merge(meta, on="code", how="left")
                    if "sector" not in uni.columns:
                        uni["sector"] = ""
                    mask = (uni["sector"].isna()) | (uni["sector"].astype(str).str.strip() == "")
                    uni.loc[mask, "sector"] = uni.loc[mask, "sector_fdr"].fillna("").astype(str)
                    if "sector_fdr" in uni.columns:
                        uni.drop(columns=["sector_fdr"], inplace=True)
        except Exception:
            pass

    # Naver Finance crawl fallback: fill remaining blank sectors (limited batch)
    try:
        mask = (uni["sector"].isna()) | (uni["sector"].astype(str).str.strip() == "")
        missing_codes = uni.loc[mask, "code"].astype(str).str.zfill(6).unique().tolist()[:200]
        if missing_codes:
            found = {}
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
                "Accept-Language": "ko-KR,ko;q=0.9"
            }
            for code in missing_codes:
                url = f"https://finance.naver.com/item/main.naver?code={code}"
                try:
                    resp = requests.get(url, headers=headers, timeout=8)
                    if resp.status_code != 200 or not resp.text:
                        continue
                    soup = BeautifulSoup(resp.text, "html.parser")
                    a = None
                    for cand in soup.find_all("a", href=True):
                        href = cand.get("href", "")
                        if "sise_group" in href and "type=upjong" in href:
                            a = cand
                            break
                    if a:
                        sec = a.get_text(strip=True)
                        if sec:
                            found[code] = sec
                    time.sleep(0.15)
                except Exception:
                    continue
            if found:
                mdf = pd.DataFrame(list(found.items()), columns=["code", "sector_nav"])
                uni = uni.merge(mdf, on="code", how="left")
                mask = (uni["sector"].isna()) | (uni["sector"].astype(str).str.strip() == "")
                uni.loc[mask, "sector"] = uni.loc[mask, "sector_nav"].fillna("")
                if "sector_nav" in uni.columns:
                    uni.drop(columns=["sector_nav"], inplace=True)
                # persist to sectors.csv
                try:
                    if len(found):
                        if SECTORS_CSV.exists():
                            s = pd.read_csv(SECTORS_CSV, dtype={"code": str})
                            s["code"] = s["code"].astype(str).str.zfill(6)
                            # update or append
                            s_map = dict(zip(s["code"], s.get("sector", "").fillna("").astype(str)))
                            s_map.update(found)
                            s_out = pd.DataFrame(list(s_map.items()), columns=["code", "sector"])
                            s_out.to_csv(SECTORS_CSV, index=False, encoding="utf-8")
                        else:
                            out = pd.DataFrame(list(found.items()), columns=["code", "sector"])
                            out.to_csv(SECTORS_CSV, index=False, encoding="utf-8")
                except Exception:
                    pass
    except Exception:
        pass

    # í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±: ì¢…ëª©ëª…ìœ¼ë¡œ ëŒ€ë¶„ë¥˜ ì¶”ì •(ë‚¨ì€ ë¹ˆ ì¹¸ë§Œ)
    try:
        def _classify_sector(name: str) -> str:
            n = (name or "").lower()
            # ë°˜ë„ì²´/ì „ìë¶€í’ˆ
            if any(k in n for k in ["ë°˜ë„ì²´", "í•˜ì´ë‹‰ìŠ¤", "ë¦¬ë…¸ê³µ", "í…Œí¬ìœ™", "í•˜ë‚˜ë§ˆì´í¬ë¡ ", "tck", "tcky", "ë™ì§„ì„ë¯¸", "ìœ ì§„í…Œí¬", "íŒŒë‘", "isc", "psk", "ì½”ë¯¸ì½”", "ì†”ë¸Œë ˆì¸", "ì†”ë¸Œë ˆì¸í™€ë”©ìŠ¤", "ì£¼ì„±ì—”ì§€ë‹ˆì–´ë§"]):
                return "ë°˜ë„ì²´"
            if any(k in n for k in ["ì „ì", "elec", "lgì´ë…¸í…", "ì‚¼ì„±ì „ê¸°"]):
                return "ì „ì/ë¶€í’ˆ"
            # 2ì°¨ì „ì§€/ì†Œì¬
            if any(k in n for k in ["ë°°í„°ë¦¬", "ì—ë„ˆì§€ì†”ë£¨ì…˜", "sdi", "ì—˜ì•¤ì—í”„", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "ì—”ì¼", "ë ˆì´í¬ë¨¸í‹°ë¦¬ì–¼ì¦ˆ"]):
                return "2ì°¨ì „ì§€"
            # ì¸í„°ë„·/í”Œë«í¼/ê²Œì„/ì½˜í…ì¸ 
            if any(k in n for k in ["naver", "ì¹´ì¹´ì˜¤", "ì¹´ì¹´ì˜¤í˜ì´", "ì¹´ì¹´ì˜¤ë±…í¬", "cj enm", "jyp", "ì™€ì´ì§€ì—”í„°", "ìŠ¤íŠœë””ì˜¤ë“œë˜ê³¤", "ë„¥ìŠ¨ê²Œì„ì¦ˆ", "ìœ„ë©”ì´ë“œ", "ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ"]):
                return "ì¸í„°ë„·/í”Œë«í¼Â·ì½˜í…ì¸ "
            # ë°”ì´ì˜¤/ì œì•½/í—¬ìŠ¤ì¼€ì–´
            if any(k in n for k in ["ë°”ì´ì˜¤", "ì œì•½", "ì…€íŠ¸ë¦¬ì˜¨", "ì”¨ì  ", "íœ´ì ¤", "ë©”ì§€ì˜¨", "ì—ìŠ¤í‹°íŒœ", "ì—˜ì•¤ì”¨ë°”ì´ì˜¤", "íë¦¬ì–¸íŠ¸", "ì•Œí…Œì˜¤ì  ", "ë„¤ì´ì²˜ì…€"]):
                return "ë°”ì´ì˜¤/ì œì•½"
            # ì •ìœ /í™”í•™/ì†Œì¬
            if any(k in n for k in ["s-oil", "s-oil", "ì •ìœ ", "í™”í•™", "lgí™”í•™", "í¬ìŠ¤ì½”ì¸í„°ë‚´ì…”ë„", "í˜„ëŒ€ì˜¤ì¼", "ì´ë…¸ë² ì´ì…˜"]):
                return "ì •ìœ /í™”í•™"
            # ìë™ì°¨/ë¶€í’ˆÂ·ëª¨ë¹Œë¦¬í‹°
            if any(k in n for k in ["í˜„ëŒ€ì°¨", "ê¸°ì•„", "ëª¨ë¹„ìŠ¤", "ì˜¤í† ì—ë²„", "ê¸€ë¡œë¹„ìŠ¤", "í•œì§„ì¹¼"]):
                return "ìë™ì°¨/ëª¨ë¹Œë¦¬í‹°"
            # ì¡°ì„ /í•´ì–‘/í•´ìš´
            if any(k in n for k in ["ì¡°ì„ ", "í˜„ëŒ€ë¯¸í¬", "ë§ˆë¦°ì†”ë£¨ì…˜", "ocean", "hmm"]):
                return "ì¡°ì„ /í•´ì–‘Â·í•´ìš´"
            # ê¸°ê³„/ì¤‘ê³µì—…Â·ë°©ì‚°
            if any(k in n for k in ["ë‘ì‚°", "hdí˜„ëŒ€ì¤‘ê³µì—…", "í•œí™”ì˜¤ì…˜", "í•œí™”ì—ì–´ë¡œ", "lignex1", "í•œêµ­í•­ê³µìš°ì£¼", "ë¡œë³´í‹±ìŠ¤"]):
                return "ê¸°ê³„/ì¤‘ê³µì—…Â·ë°©ì‚°"
            # ê¸ˆìœµ(ì€í–‰/ì¦ê¶Œ/ë³´í—˜/ì§€ì£¼)
            if any(k in n for k in ["ê¸ˆìœµ", "ì€í–‰", "ì¦ê¶Œ", "ë³´í—˜", "ì§€ì£¼", "kb", "ì‹ í•œ", "í•˜ë‚˜ê¸ˆìœµ", "bnk", "í‚¤ì›€ì¦ê¶Œ", "nhíˆ¬ì"]):
                return "ê¸ˆìœµ"
            # í†µì‹ /ë¯¸ë””ì–´/ìœ í†µ
            if any(k in n for k in ["í†µì‹ ", "skí…”ë ˆì½¤", "kt", "lgìœ í”ŒëŸ¬ìŠ¤"]):
                return "í†µì‹ "
            # ìœ í†µ/ì†Œë¹„ì¬
            if any(k in n for k in ["ì•„ëª¨ë ˆ", "gs", "cj", "ì½”ì›¨ì´", "ì‚¼ì–‘ì‹í’ˆ", "ë§¥ì¿¼ë¦¬ì¸í”„ë¼"]):
                return "ì†Œë¹„ì¬/ìœ í†µ"
            return ""

        mask_kw = (uni["sector"].isna()) | (uni["sector"].astype(str).str.strip() == "")
        if mask_kw.any():
            uni.loc[mask_kw, "sector"] = uni.loc[mask_kw, "name"].apply(_classify_sector).fillna("")
    except Exception:
        pass

    # sectors.csvì— ì—†ë˜ ì¢…ëª©ì€ ì´ì „ universe.csvì˜ sectorë¥¼ ë³´ì¡´
    if "sector" not in uni.columns:
        uni["sector"] = ""
    try:
        if old_sector_map:
            mask = (uni["sector"].isna()) | (uni["sector"].astype(str).str.strip() == "")
            uni.loc[mask, "sector"] = uni.loc[mask, "code"].map(old_sector_map).fillna("")
        uni["sector"] = uni["sector"].fillna("").astype(str)
    except Exception:
        pass

    # ì €ì¥ ì»¬ëŸ¼ ìˆœì„œ ê³ ì •
    cols = [c for c in ["code", "name", "market", "sector"] if c in uni.columns]
    uni = uni[cols]

    # sector í…œí”Œë¦¿ ìƒì„±(sectors.csv ë¯¸ì¡´ì¬ ì‹œ 1íšŒì„± ê°€ì´ë“œ íŒŒì¼ ìƒì„±)
    try:
        template_path = DATA_DIR / "sectors_template.csv"
        if not SECTORS_CSV.exists():
            tmp = uni[["code"]].copy()
            tmp["sector"] = ""
            tmp.to_csv(template_path, index=False, encoding="utf-8")
    except Exception:
        pass

    # ì €ì¥
    uni.to_csv(UNIVERSE_CSV, index=False, encoding="utf-8")
    logging.info(f"Saved universe: {UNIVERSE_CSV.resolve()} (rows={len(uni)})")

    # DB upsert
    # Save to DB (prefer Postgres via SQLAlchemy engine)
    try:
        if get_engine:
            eng = get_engine()
            uni.to_sql("stocks", eng, if_exists="replace", index=False)
            logging.info("Saved universe to Postgres via SQLAlchemy (rows=%d)", len(uni))
            return
    except Exception:
        logging.exception("SQLAlchemy save failed, fallback to sqlite")

    conn = None
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.execute("PRAGMA foreign_keys = ON;")
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS stocks (
                code        TEXT PRIMARY KEY,
                name        TEXT NOT NULL,
                market      TEXT,
                sector      TEXT,
                listed_at   DATE,
                delisted_at DATE
            );
            """
        )
        uni.to_sql("stocks", conn, if_exists="replace", index=False)
        conn.commit()
        logging.info("Saved universe to sqlite DB: %s (rows=%d)", DB_PATH.resolve(), len(uni))
    except Exception:
        logging.exception("Failed to save universe to sqlite DB")
    finally:
        try:
            if conn:
                conn.close()
        except Exception:
            pass


if __name__ == "__main__":
    main()
