먼저 한 줄 요약부터 할게요.
**Lee_trader는 “한국 주식 유니버스 전체를 매일 스캔해서, 예측 리턴·리스크·퀄리티를 합쳐 점수화하고, 그걸 SQLite+Node 대시보드로 매매 의사결정까지 연결하는 ‘개인 퀀트 리서치/운용 시스템’**이에요.

이걸 기준으로 아키텍처 / 구조 / 목적·목표 / 현재 적용사항 / 앞으로 개선사항 + Codex 활용 방향까지 정리해볼게요.

---

## 1. 프로젝트 목적 & 철학

### 1.1 근본 목적

1. **한국 주식 시장 전체를 정량적으로 스캔**

   * KOSPI/KOSDAQ 등 주요 종목을 매일 “유니버스”로 정의하고,
   * 시가총액, 거래대금, 거래량 등으로 투자 가능한 종목만 필터링.

2. **중·단기(60일, 90일)를 보는 ML 기반 예측·점수화**

   * 목표:

     * 60일·90일 수익률 예측(`pred_return_60d`, `pred_return_90d`)
     * 그 기간 중 최대 낙폭(MDD) 예측(`pred_mdd_60d`, `pred_mdd_90d`)
     * 상위 20% 안에 들 확률(`prob_top20_60d`, `prob_top20_90d`)

3. **예측값 + 리스크 + 퀄리티를 통합한 “점수/랭킹”**

   * 예측 수익률, 퀄리티, 시장 상황, 예상 MDD 등을 합성한 `final_score`를 계산.
   * 이걸 기준으로 매일 “Top N 종목 리스트”를 만든 뒤,
   * 실제 매매/보유/청산 의사결정을 돕는 리포트까지 연결.

4. **백테스트 + 페이퍼 트레이딩으로 검증**

   * `score_backtest_from_labels.py`, `backtest.py`, `backtest_walkforward.py` 등으로
     전략 수익률을 검증.
   * `paper_trading_tracker.py`, Node의 `trades` 테이블로 “모의 운용 일지” 기록.

### 1.2 설계 철학 (지금 구조에 녹아있는 생각들)

* **완전 자동화보다는 “리서치 + 의사결정 도우미”**

  * 지금은 실계좌 자동주문보다는
    “매일 랭킹/리포트 → 사람이 보고 결정” 구조.
* **모든 결과는 CSV/DB로 남기고 재현 가능하게**

  * `data/` 폴더 내 각 단계별 CSV,
  * `migrate_to_sqlite.py`를 통해 SQLite로 통합 → Node 대시보드에서 사용.
* **로컬·Docker 어디서든 돌아가는 배치 시스템**

  * `docker-compose.yml`로 Python 파이프라인 컨테이너 + Node API 컨테이너 분리.
* **설명 가능한 구조**

  * 큰 모델 하나의 블랙박스가 아니라,

    * 유니버스 선택
    * 피처/라벨 생성
    * 모델 학습
    * 점수 계산
    * 랭킹/리포트
      단계를 분리해서 “어디서 어떤 계산을 하는지”가 문서와 코드로 드러나게.

---

## 2. 전체 아키텍처 한눈에 보기

### 2.1 논리 아키텍처

```text
[외부 데이터 소스]
  - KIS API, pykrx, Naver, DART 등
        │
        ▼
[Python 파이프라인 (배치)]
  1) fetch_market_data.py         → market_status.csv
  2) fetch_top_universe.py        → universe.csv
  3) download_prices_kis.py       → prices_daily_raw.csv
  4) clean_prices.py              → prices_daily_clean.csv
  5) create_adjusted_prices.py    → prices_daily_adjusted.csv
  6) fetch_fundamentals_dart.py   → fundamentals.csv
  7) quality_builder.py           → quality.csv
  8) feature_builder.py           → features.csv
  9) label_builder.py             → labels.csv
 10) model_train.py / _optuna.py  → model.pkl
 11) model_predict.py             → predictions.csv
 12) scoring.py                   → scores_final.csv
 13) ranking_builder.py           → ranking_final.csv, history/*
        │
        ▼
[데이터 저장]
  - data/*.csv
  - migrate_to_sqlite.py → data/lee_trader.db (SQLite)
        │
        ▼
[Node API + Web UI]
  - node/index.js (Express + better-sqlite3)
  - public/*.html, *.js
  - /api/ranking, /api/trades, /api/holdings 등
        │
        ▼
[사용자]
  - 브라우저로 Top20 랭킹, 보유종목 성과, 거래 기록 등을 확인
  - PRD/리포트를 기반으로 매수·매도 의사결정
```

### 2.2 물리 아키텍처 (로컬 + Docker 기준)

* **컨테이너 1: python-pipeline**

  * `python/Dockerfile` 기반
  * `command: ["python", "python/run_pipeline.py"]`
  * `./data`를 `/app/data`로 마운트 → 결과 CSV를 로컬에 남김

* **컨테이너 2: node-api**

  * `node/Dockerfile` 기반
  * `command: ["npm", "run", "start"]`
  * `./data`를 `/app/data`로 마운트 → 같은 데이터/DB에 접근
  * 3000포트로 API+정적 페이지 제공

* **공통 설정**

  * `.env` / `.env.example` 에 KIS, DART 등 API 키와 설정
  * `logs/` 디렉토리에 파이프라인 로그

---

## 3. 코드/디렉토리 구조

### 3.1 루트

* `.dockerignore`
* `.env.example` → 운영에 필요한 환경변수 샘플
* `docker-compose.yml` → 두 컨테이너(python, node) 오케스트레이션
* `bootstrap.ps1` → Windows 환경 초기 세팅/실행용 스크립트
* `migrate_to_sqlite.py` → CSV → SQLite 변환
* `naver_price_downloader.py` → 별도 Naver 데이터 수집 보조 스크립트
* `score_backtest.py`, `score_backtest_from_labels.py` → 점수 기반 전략 백테스트
* `data/` → 모든 CSV + 분석 결과 + lee_trader.db
* `logs/` → 파이프라인 실행 로그
* `python/` → 파이프라인 및 모델 관련 Python 코드
* `node/` → Express 기반 API + UI
* `scripts/` → `run_pipeline.cmd`, `pack_for_home.ps1` 등 유틸

### 3.2 `python/` 폴더 – 파이프라인 & 모델

대략 아래 그룹으로 나뉘어 있어요.

#### (1) 데이터 수집 & 전처리

* `fetch_market_data.py`

  * 지수 수준, 이동평균, 거래대금, 외국인 수급 등 시장 상태 지표 생성.
  * `market_status.csv` 출력.
* `fetch_top_universe.py`

  * 시가총액, 거래대금, 상장주식수 등을 기준으로
    “오늘 매매대상이 될 수 있는 종목 리스트”(`universe.csv`) 생성.
* `download_prices_kis.py`

  * KIS API + pykrx로 유니버스 종목 과거 OHLCV 수집 → `prices_daily_raw.csv`.
* `clean_prices.py`

  * 결측치, 비정상 가격, 상폐 구간 등 정제 → `prices_daily_clean.csv`.
* `create_adjusted_prices.py`

  * 액면분할/무상증자 등 이벤트 고려해 `prices_daily_adjusted.csv` 생성.

#### (2) 재무/퀄리티

* `fetch_fundamentals_dart.py`

  * Dart/재무 데이터 수집 → `fundamentals.csv`.
* `quality_builder.py`

  * ROE, 영업이익률, 부채비율, 현금흐름 등에서
    z-score/클리핑/가중합으로 `quality_score` 계산 → `quality.csv`.

#### (3) 피처 & 라벨

* `feature_builder.py`

  * 가격 기반 피처 (모멘텀, 변동성, 이동평균 대비 괴리율, 거래량 등) 생성.
  * `features.csv` 출력 (date, code, feature_…).
* `label_builder.py`

  * D+60, D+90 수익률(`target_60d`, `target_90d`) 계산.
  * 상위 20% 여부 이진 라벨(`target_60d_top20`, `target_90d_top20`) 생성.
  * `labels.csv` 출력.

#### (4) 모델 학습 & 예측

* `model_train.py`

  * `features.csv` + `labels.csv`를 조인해서 학습용 데이터셋 구성.
  * scikit-learn / xgboost / lightgbm 기반 회귀·분류 모델 학습.
  * 모델을 `model.pkl`로 저장.
* `model_train_optuna.py`

  * Optuna를 이용한 자동 하이퍼파라미터 튜닝 버전.
* `model_predict.py`

  * `model.pkl` + 오늘자의 피처로 예측 수행.
  * `predictions.csv` 출력

    * `pred_return_60d`, `pred_return_90d`
    * `pred_mdd_60d`, `pred_mdd_90d`
    * `prob_top20_60d`, `prob_top20_90d` 등.

#### (5) 점수/랭킹 & 분석

* `scoring.py`

  * 예측값 + quality_score + 시장상황 + 리스크 패널티 등을 합성해

    * `score`, `pred_score`, `ret_score`, `prob_score`, `qual_score`, `final_score` 계산.
  * `scores_final.csv` 출력.
* `ranking_builder.py`

  * `scores_final.csv` + 시가총액/유동성/시장 상태 등을 추가 반영해
    최종 랭킹(`ranking_final.csv`) 생성.
  * 동시에 `/data/history/YYYYMMDD_ranking.csv` 같은 히스토리 파일도 누적.

#### (6) 백테스트 & 페이퍼 트레이딩

* `backtest.py`, `backtest_walkforward.py`

  * 특정 점수/전략(예: 상위 20종목 동일비중 매수) 기준 백테스트.
  * 리밸런스 주기, 거래비용, 홀딩 기간 등을 바꿔가며 실험.
* `score_backtest.py`, `score_backtest_from_labels.py`

  * `labels.csv`와 점수(`score`, `final_score`)를 이용해
    “과거에 이 점수 기준으로 샀으면 어땠나”를 검증.
* `paper_trading_tracker.py`, `paper_trading_report.py`

  * 실제 매매 대신 CSV나 DB에 트랜잭션 기록.
  * 손익, 승률, MDD, CAGR 등 요약 리포트 생성.

#### (7) 실행 오케스트레이션

* `run_pipeline.py`

  * 위의 단계들을 `STEPS` 리스트로 정의해서 순차 실행.
  * 에러 발생 시 로그 남기고 중단.
  * Docker 컨테이너의 엔트리포인트.

#### (8) 기타

* `schemas.py`

  * Pydantic 모델 (ActionItem, TodayActionResponse 등)
  * 향후 FastAPI 기반 대시보드/추천 API를 염두에 둔 구조.
* `dashboard.py`

  * FastAPI + SQLAlchemy 기반의 `/api/dashboard` 스켈레톤.
  * 아직 requirements에 fastapi/sqlalchemy가 없어서 “미사용/미완성 초안” 상태에 가깝고,
    향후 Python API 서버로 확장할 때 씨앗 역할.

---

### 3.3 `migrate_to_sqlite.py` – 데이터 레이어 통합

* `data/*.csv` → `data/lee_trader.db`로 옮기면서 아래 테이블 생성:

  * `stocks` (universe, 종목 메타)
  * `daily_ranking`
  * `daily_scores`
  * `labels`
  * `backtest_trades`
  * `market_status`
  * `prices_raw`, `prices_clean`, `prices_adjusted`
  * `fundamentals`, `quality`, `features`, `predictions`
  * `trades` (실제/페이퍼 트레이딩 기록) – CSV도 함께 관리

* 장점

  * Node API가 SQL로 쉽게 조회 가능
  * 히스토리 쿼리, 집계, 필터링 유연해짐

* 현재 상태

  * CSV와 DB가 “둘 다” 존재 → 소스 오브 트루스가 이원화.
  * 추후 “파이프라인은 곧바로 DB에 쓰고, CSV는 export 옵션”으로 정리 가능.

---

### 3.4 `node/` – Express API & 웹 대시보드

#### 핵심 파일

* `node/index.js`

  * `express`, `cors`, `better-sqlite3` 사용.
  * `resolveDataDir()`로 `/app/data`, `node/data`, `../data` 등 후보에서 데이터 디렉토리 탐색.
  * `lee_trader.db` 연결 + `trades` 테이블 보장.
  * 주요 기능:

    * 최신 랭킹 불러오기 (`dbLatestRanking`)
    * 예측/점수/라벨 등 조회
    * 거래 목록/보유 종목 계산
    * 정적 HTML/JS 서빙

* `node/public/*.html`, `*.js`

  * `index.html` / `ranking.html` / `holdings.html` / `holdingsDetail.html` / `trade-history.html` 등
  * API에서 가져온 데이터를 테이블/차트로 보여주는 미니 대시보드.

* `node/data/` (있다면)

  * 로컬 개발 시 CSV/DB를 여기에 둘 수도 있음 (하지만 Docker 기준으로는 루트 `data/`와 공유).

---

## 4. 현재 “적용사항” 정리

### 4.1 어떤 전략/아이디어가 구현되어 있나

1. **유니버스 필터링**

   * 시총, 거래대금, 유동성 기준으로
     “실제 매매 가능하고, 너무 작은 잡주는 제외”하는 룰 적용.

2. **기술 + 펀더멘탈 + 시장 상태 통합**

   * 가격 기반 기술 지표 (모멘텀, 변동성, 이동평균, RSI 등)
   * 재무 기반 퀄리티 스코어 (ROE, 마진, 부채비율, 현금흐름)
   * 지수 레벨, 외국인 수급, 변동성 등 시장 레짐

3. **다중 목적 예측**

   * 수익률 예측(회귀) + 상위20% 여부 예측(분류) + MDD 예측.
   * 예:

     * `pred_return_60d`가 높은데
       `pred_mdd_60d`가 너무 크면 패널티를 준다.
     * `prob_top20_60d`가 높으면 점수에 보너스.

4. **점수 체계**

   * `ret_score`: 예측 수익률 기반 점수
   * `prob_score`: 상위20% 확률 기반 점수
   * `qual_score`: 퀄리티/재무 기반 점수
   * `pred_score`: 모델 자체의 예측 신뢰도/보조
   * `final_score`: 위들을 적절히 섞고, 리스크 패널티 + 시장 레짐 반영.

5. **전략 검증**

   * `final_score` 상위 N개를 매일 또는 특정 주기마다 매수했다면?
   * 실제 과거 수익률(라벨)을 기준으로 승률/평균 수익률/MDD 계산.

6. **대시보드**

   * Top20 랭킹
   * 보유 종목별 평가손익, 비중, MDD
   * 거래 히스토리
   * 히스토리 랭킹 비교 (향후 확장 여지)

---

## 5. 앞으로의 개선사항 (로드맵 + Codex 활용 포인트)

여기부터가 “v5 이후”에 할 만한 목록이에요. Codex(= VS Code용 GPT 코드 모델들)와 같이 쓰기 좋게, **개발 작업 단위**로 쪼개서 적어볼게요.

### 5.1 인프라 & DevEx

1. **환경 분리 & 패키지 매니저 정리**

   * 지금: requirements.txt + Docker 기반.
   * 개선:

     * `pyproject.toml`(uv/poetry) 도입해서 의존성 관리 명확히.
     * `requirements-dev.txt`로 dev / prod 의존성 분리.
   * Codex 활용:

     * “이 `requirements.txt` 기반으로 pyproject.toml 생성해줘.”
     * “Dockerfile을 멀티스테이지 빌드로 최적화해줘.”

2. **Windows + Docker 워크플로우 정리**

   * `bootstrap.ps1`, `run_pipeline.cmd`가 흩어져 있는데,
   * 하나의 `make.ps1` 또는 `tasks.json`(VS Code)로 통합:

     * `task: dev-start`, `task: pipeline-run`, `task: migrate-db` 등.
   * Codex 활용:

     * VS Code tasks 생성/수정 자동화.

3. **로깅/모니터링 강화**

   * 현재: `logging.basicConfig` 수준.
   * 개선:

     * JSON 로그로 바꾸고,
     * 각 스텝 실행 시간/입력 레코드 수/출력 레코드 수를 메트릭으로 기록.
   * Codex 활용:

     * `run_step`에 데코레이터 패턴 적용해 공통 로깅/타이밍 코드 생성 요청.

4. **테스트 코드 도입**

   * 현재: 테스트 폴더 없음.
   * 개선:

     * `tests/` 폴더 만들고,
     * 각 모듈별 최소 단위테스트 정의 (라벨 계산, 품질 점수 계산 등).
   * Codex 활용:

     * “이 함수에 대한 pytest 테스트 5개 만들어줘.”
     * 엣지 케이스까지 제안 받기.

---

### 5.2 데이터 & 모델 측면

1. **피처 엔지니어링 고도화**

   * 추가 후보:

     * 팩터(가치, 퀄리티, 모멘텀, 사이즈) 명확 분리
     * 섹터/산업 더미 변수
     * 마켓 레짐(상승장/횡보장/하락장) one-hot
     * 이벤트(실적 발표, 액면분할, 공시 등) 피처
   * Codex 활용:

     * “이 논문/블로그에서 나온 팩터 목록을 코드로 피처 빌더에 넣어줘.”
     * “기존 feature_builder.py 구조 유지하면서 피처 X,Y,Z를 추가해줘.”

2. **데이터 검증 (Data Validation)**

   * 현재는 정제 로직만 있고, “이상치 리포트”는 없음.
   * 개선:

     * `great_expectations`나 pydantic 기반으로
       각 CSV에 대해 스키마/범위 체크.
   * Codex 활용:

     * “이 CSV 컬럼 정의를 기반으로 pydantic 모델/검증 코드를 만들어줘.”

3. **모델 앙상블 & 리스크 모델 분리**

   * 지금은 회귀/분류를 묶어 쓰지만,
   * 개선:

     * 수익률 예측 모델, MDD 예측 모델, 레짐 분류 모델을 분리하고 앙상블.
   * Codex 활용:

     * “이 세 개의 모델을 학습하고 예측을 병합하는 파이프라인 클래스를 만들어줘.”

4. **Walk-forward / Time-series CV 정교화**

   * `backtest_walkforward.py`를 더 정교하게:

     * 롤링 윈도우, 확장 윈도우, 월단위 리밸런싱 등 파라미터화.
   * Codex 활용:

     * “이 backtest 함수를 클래스 기반 시뮬레이터로 리팩토링해줘.”

5. **모델 모니터링**

   * 예측 수익률 vs 실제 수익률 비교를 자동 리포트:

     * 히트맵, 캘리브레이션 곡선 등.
   * Codex 활용:

     * matplotlib 코드 자동 생성 (차트 템플릿).

---

### 5.3 DB & API 레이어 개선

1. **DB 스키마 명시화**

   * 지금: `migrate_to_sqlite.py` 안에 CREATE TABLE 쿼리들이 숨어 있음.
   * 개선:

     * `/db/schema.sql` 혹은 `/db/migrations/` 디렉토리를 만들어

       * “DDL은 여기, 로직은 Python/Node”로 분리.
   * Codex 활용:

     * “이 SQLite 연결 코드에서 현재 사용 중인 테이블 정의를 추출해 schema.sql 작성해줘.”

2. **CSV vs DB 이원화 정리**

   * 최종 목표:

     * 파이프라인은 DB를 기준으로 쓰고,
     * 필요할 때만 CSV export.
   * 단계:

     * `run_pipeline.py` 마지막에 `migrate_to_sqlite.py` 호출 (또는 각 step이 DB에 직접 write).
   * Codex 활용:

     * “이 pandas to_csv() 부분을 to_sql()로 바꾸고, 인덱스/타입 설정 코드 만들어줘.”

3. **Node API 확장**

   * 현재는 데이터 조회 위주.
   * 확장 아이디어:

     * `/api/ranking/:date` (과거 날짜 기준 랭킹)
     * `/api/stock/:code/history` (종목별 랭킹/점수 히스토리)
     * `/api/strategy/backtest?params=...` (간단한 백테스트 API)
   * Codex 활용:

     * 기존 패턴 따라 새 라우터/쿼리 추가 코드 자동 생성.

4. **Python FastAPI 서버 통합(선택)**

   * 이미 `dashboard.py`, `schemas.py` 스켈레톤이 있으니,
   * 선택지:

     1. Node API 그대로 두고, Python은 배치 전용
     2. Python에 FastAPI 서버를 추가해 “추천/리서치 API”를 맡김
   * Codex 활용:

     * “이 Pydantic 스키마 기반으로 FastAPI 엔드포인트 3개 만들어줘.”

---

### 5.4 프론트엔드 & UX

1. **UI 모듈화**

   * 현재: `public/*.html` + 기본 JS.
   * 개선:

     * 최소한 컴포넌트화 (React/Vue/HTMX 어떤 걸 선택하든).
     * 예:

       * `<TopRankingTable />`
       * `<HoldingsSummary />`
       * `<TradeHistory />`
   * Codex 활용:

     * “이 HTML+JS코드를 React 컴포넌트로 옮겨줘.”

2. **“오늘 해야 할 일” 대시보드**

   * `TodayActionResponse`(buy/add/trim candidates)를 실제 UI로:

     * 오늘 날짜, Top buy/add/trim 리스트
     * 각 종목별 이유(reason 문자열) 표시
   * Codex 활용:

     * API 응답 예시를 주고, 그걸 카드 형식 UI로 렌더링하는 코드 생성.

3. **리포트 자동 생성**

   * 매일 아침:

     * Top20 표 + 간단한 마켓 코멘트 + 리스크 지표 정리해서
     * HTML/Markdown 리포트 생성.
   * Codex 활용:

     * “이 DataFrame을 기반으로 하루 리포트를 Markdown 템플릿에 채워줘.”

---

### 5.5 리스크 관리 & 실매매로의 확장

1. **리스크 버짓 시스템**

   * 종목별 최대 비중, 섹터별 최대 비중, 하루 손실 한도 등을 룰로 정의.
   * 포트폴리오 구성 단계에서 이 제약조건을 적용.
   * Codex 활용:

     * “이 단순 equal-weight 포트폴리오 생성 코드를
       리스크 버짓 기반 최적화(선형 제약조건) 코드로 바꿔줘.”

2. **브로커 API 연동 (장기 목표)**

   * 한국투자, 키움 등 API로 실매매 자동화.
   * 단계:

     * paper → pseudo-order → 실제 주문
   * Codex 활용:

     * HTTP/Socket API 래퍼 생성, 에러 핸들링 템플릿 작성 등.

---

### 5.6 Codex와 함께 발전시키는 “작업 루틴” 제안

마지막으로, 이 프로젝트를 Codex/GPT 기반으로 꾸준히 키우려면,
**“작업 단위 + 프롬프트 패턴”**을 정해두는 게 좋아요.

1. **작업 단위 예시**

   * [ ] feature_builder 리팩토링 + 새 팩터 추가
   * [ ] label_builder에 multiple horizon 추가 (30d, 180d)
   * [ ] backtest_walkforward를 클래스로 리팩토링
   * [ ] migrate_to_sqlite를 ORM(Alembic) 구조로 분리
   * [ ] Node ranking API에 날짜 파라미터 추가
   * [ ] React 기반 간단 대시보드로 교체

2. **프롬프트 패턴 예시**

   * “이 파일 전체를 준다 → 리팩토링/주석/테스트 생성 요청”
   * “이 함수의 입출력 스펙만 설명 → 새 구현 요청”
   * “현재 PRD 설명을 바탕으로 새 모듈 설계 초안 요청”

3. **VS Code 연동 패턴**

   * 코드 선택 → “이 부분 설명해줘”
   * 폴더 단위 → “이 구조를 다이어그램/README로 요약해줘”
   * 새 파일 → “기존 구조에 맞는 새 모듈 기본 뼈대 만들어줘”

---

## 6. 마무리

정리해보면, 지금 Lee_trader는 이미:

* **데이터 수집 → 전처리 → 피처/라벨 → 모델 → 점수/랭킹 → DB → 대시보드**
  이 전체 파이프라인이 “한 번은 끝까지 통으로 돌아가는” 상태예요.
* 백테스트/페이퍼 트레이딩도 붙어있어서,
  단순 실험용이 아니라 “실제 운용에 근접한 개인 퀀트 시스템” 단계에 와 있고요.

앞으로는:

* **DevEx 정리 + 테스트/로그 + DB/CSV 정리**
* **모델/피처 고도화 + UI/리포트 고도화**
* **(장기적으로) 리스크/실매매까지**

이 세 축을 중심으로 Codex를 적극 활용하면,
정말 “개인 리서치룸 + 개인 운용 시스템” 느낌까지 충분히 갈 수 있는 구조라고 보면 될 것 같아요.

이 다음엔 원하면,

* “v5 로드맵”을 체크리스트 형식으로 쪼개서
* GitHub 이슈/프로젝트 보드에 바로 옮길 수 있는 형태로도 정리해줄게요.
