일단 결론부터 말하면,
**지금 파이프라인 구조 / CSV–DB 매칭은 전체적으로 잘 맞게 설계돼 있고, DB화도 정상적으로 돌아가는 상태야.**
(앞에서 `realized_return_*` 이슈만 잘 정리해서 모델 재학습하면 큰 문제는 없음)

내가 전체 흐름을 **“어느 파이썬 파일이 어떤 CSV를 만들고, 어떤 DB 테이블에 박는지”** 기준으로 한 번 쫙 정리해볼게.

---

## 1. 원천 데이터 라인: 가격/유니버스/시장상태

### 1) 종목 유니버스

* **파일들**

  * `data/universe_base.csv` : 자동 추출된 기본 유니버스
  * `data/interest_universe.csv` : 네가 수동으로 추가한 관심 종목
  * `data/universe.csv` : 최종 유니버스 (이걸 전체 파이프라인이 사용)
* **파이썬**

  * `fetch_top_universe.py` → `universe_base.csv` 생성
  * `merge_universe.py`

    * 입력: `universe_base.csv`, `interest_universe.csv`
    * 출력: `universe.csv`
    * name / market / sector 없으면 컬럼 만들어서 채워놓음
* **DB**

  * `stocks` 테이블 구조

    * `code, name, market, sector, listed_at, delisted_at`
  * 지금 구조상:

    * 유니버스는 CSV 기준으로 쓰고,
    * DB의 `stocks`는 “메타 테이블” 용도 (향후 확장용)으로 맞춰져 있음.
  * **불일치 없음.** 다만 앞으로 업그레이드 때:

    * `universe.csv` → `stocks`로 싱크시키는 스텝 하나 넣으면 더 깔끔해짐.

---

### 2) 가격 데이터 (raw → clean → adjusted)

#### a. KIS/pykrx에서 가격 내려받기

* **파이썬**: `download_prices_kis.py`
* **CSV**

  * 입력: `data/universe.csv` (티커 목록)
  * 출력: `data/prices_daily_raw.csv`
* **DB**

  * `prices_raw` 테이블에 동일한 구조로 INSERT
  * 스키마:

    * `date, code, open, high, low, close, volume` (PK: date+code)
* **상태**

  * CSV 컬럼과 DB 컬럼 이름/순서가 정확히 맞고,
  * PK도 `date+code`로 통일되어 있어서 이후 조인에 문제 없음.

#### b. 클렌징

* **파이썬**: `clean_prices.py`
* **CSV**

  * 입력: `prices_daily_raw.csv`
  * 출력: `prices_daily_clean.csv`
* **DB**

  * `prices_clean` 테이블에 동일 구조로 INSERT
  * 스키마도 `prices_raw`와 동일 (date, code, open, high, low, close, volume)
* **상태**

  * 이름/타입/PK 모두 raw와 일치 → OK

#### c. 액면분할/병합 보정 (adjusted)

* **파이썬**: `create_adjusted_prices.py`
* **CSV**

  * 입력: `prices_daily_clean.csv`
  * 출력: `prices_daily_adjusted.csv`
* **DB**

  * `prices_adjusted` 테이블

    * `date, code, adj_open, adj_high, adj_low, adj_close, volume` (PK: date+code)
* **상태**

  * CSV와 테이블 스키마가 1:1 매칭.
  * 이후 라벨 계산(`label_builder.py`)과 `fact_price_daily` 구성의 기반이 됨.

#### d. fact_price_daily (집계용)

* **DB**

  * `fact_price_daily` 테이블 존재
  * 구조는 “조인/리포트용 집계 테이블” 형태로 잘 짜여 있음.
* **파이썬**

  * 현재 파이프라인에서 필수는 아니고, 보고/확장용으로 설계돼 있음.
  * 깨진 참조는 없음.

---

### 3) 시장 상태 (Market Regime)

* **파이썬**: `fetch_market_data.py`
* **CSV**

  * `data/market_status.csv`
  * 컬럼: `date, kospi_close, kospi_ma20, volatility_5d, foreign_net_5d, market_up`
* **DB**

  * `market_status` 테이블
  * 스키마가 CSV와 정확히 매칭
* **사용처**

  * `ranking_builder.py`에서 최종 랭킹에

    * `market_up, market_status_date, market_kospi_close, market_kospi_ma20, market_vol_5d, market_foreign_5d`
    * 이런 필드를 붙여서 **점수 + 시장상태 메타**를 함께 저장.

---

## 2. 펀더멘탈 → 퀄리티 → 피처

### 1) 펀더멘탈 (OpenDART)

* **파이썬**: `fetch_fundamentals_dart.py`

  * 입력: `universe.csv` 또는 `features.csv`의 code 목록
  * 출력:

    * `fundamentals.csv`
    * DB `fundamentals` 테이블
* **상태**

  * 펀더멘탈 정보는 이후 `quality_builder.py`에서 소비.

### 2) 퀄리티 스코어

* **파이썬**: `quality_builder.py`

  * 입력: `fundamentals.csv`
  * 출력: `quality.csv`

    * 컬럼: `date, code, quality_score`
  * DB: `quality` 테이블

    * 구조 동일 (`date, code, quality_score`, PK: date+code)
* **상태**

  * CSV ↔ DB 완전히 일치
  * `feature_builder.py`에서 이 `quality_score`를 merge해 사용.

### 3) 피처(Features)

* **파이썬**: `feature_builder.py`

  * 입력:

    * `prices_daily_clean.csv` (또는 adjusted)
    * `quality.csv` (퀄리티 병합용)
  * 출력: `features.csv`

    * 컬럼(요약):

      * `date, code, close,
         ret_1d, ret_5d, ret_10d,
         mom_20,
         ma_5, ma_20, ma_60,
         close_over_ma20,
         vol_20, vol_60,
         rsi_14,
         volume, vol_ma_20, vol_ratio_20,
         quality_score`
  * DB: `features` 테이블

    * 스키마가 위와 정확히 일치 (PK: date+code)
* **상태**

  * 실제 `features.csv`와 DB 테이블 컬럼 모두 확인했을 때 완전히 동일.
  * 이후 **모델 학습 / 예측 / 랭킹에서 이 구조를 기준으로 사용**하고 있음.

---

## 3. 라벨 / 백테스트용 타깃

### 1) 라벨 생성

* **파이썬**: `label_builder.py`

  * 입력: `prices_daily_adjusted.csv`
  * 출력: `labels.csv`

    * 컬럼(핵심):

      * `date, code`
      * `target_30d, target_60d, target_90d`
      * `target_log_30d, target_log_60d, target_log_90d`
      * `target_mdd_30d, target_mdd_60d, target_mdd_90d`
      * `target_30d_top20, target_60d_top20, target_90d_top20`
      * `realized_return_30d, realized_return_60d, realized_return_90d`
  * DB: `labels` 테이블

    * 스키마가 위와 정확히 일치.
* **상태**

  * CSV / DB 모두 동일 스키마.
  * **realized_return_* 컬럼은 DB/CSV에만 존재하고 features에는 없음 → 이게 맞는 구조**
    (미래 수익률은 라벨/백테스트용 데이터지, 실전 예측 feature가 아니니까)

---

## 4. 모델 학습 & 예측

### 1) 모델 학습

* **파이썬**: `model_train.py`

  * 입력:

    * `features.csv`
    * `labels.csv`
  * 내부에서:

    * `features` + `labels`를 `date, code`로 merge
    * 여기서 **타깃 컬럼들(target_*, **top20, realized_return**)는 feature에서 제외**해야 함
      (우리가 얘기한 대로 수정해두면 OK)
  * 출력:

    * `model.pkl` (LightGBM 등 파라미터 + `pack["features"]` 목록 저장)
  * DB:

    * 직접 쓰는 건 없음 (모델 파일만)

* **체크 포인트**

  * `pack["features"]` 안의 컬럼 목록이 **features.csv 컬럼들과 100% 동일**해야 함
  * 지금 구조 기준으로:

    * `realized_return_*`는 feature에서 빠져야 하고,
    * 나머지 18개 피처는 전부 들어가야 정상.

### 2) 모델 예측

* **파이썬**: `model_predict.py`

  * 입력:

    * `features.csv`
    * `model.pkl`
  * 내부:

    * `pack["features"]` 기준으로 `features.csv`에서 최신 날짜 레코드 선택
    * 예측 값:

      * `pred_return_60d, pred_return_90d`
      * `pred_mdd_60d, pred_mdd_90d`
      * `prob_top20_60d, prob_top20_90d`
      * `score` (모델 자체 스코어)
  * 출력:

    * `predictions.csv` (위 컬럼 + date, code)
    * `prediction_history_*.csv` (히스토리용)
  * DB:

    * `predictions` 테이블

      * 컬럼: `date, code, pred_return_60d, pred_return_90d, pred_mdd_60d, pred_mdd_90d, prob_top20_60d, prob_top20_90d, score`
    * CSV와 테이블 스키마가 정확히 매칭.

* **상태**

  * 예측 결과는 CSV + DB 양쪽 모두 같은 구조로 들어가 있어서
  * 이후 점수/랭킹 단계에서 그대로 소비 가능.

---

## 5. 점수 계산 / 랭킹 / 최종 결과

### 1) 점수 계산 (composite scoring)

* **파이썬**: `scoring.py`

  * pure 함수 모듈 (I/O 없음)
  * 입력 DataFrame에 대해:

    * `ret_score, prob_score, qual_score, tech_score, pred_score, risk_penalty, market_regime_score, final_score_v5` 등 생성
  * 이걸 실제로 사용하는 스크립트는:

    * `analysis/` 아래 백테스트용
    * 또는 `scores_final.csv`를 만드는 별도 스크립트 (이미 생성돼 있음)

* **CSV / DB**

  * `scores_final.csv` → per-date, per-code 점수.
  * DB: `daily_scores` 테이블

    * 구조:

      * `date, code, ret_score, prob_score, qual_score, tech_score, pred_score, risk_penalty, market_regime_score, final_score_v5`
  * 스키마 일치 확인됨.

### 2) 최종 랭킹

* **파이썬**: `ranking_builder.py`

  * 입력:

    * `predictions.csv`   (모델 예측)
    * `scores_final.csv`  (composite score)
    * `features.csv`      (close, quality_score, 기술지표)
    * `universe.csv`      (name, market, sector)
    * `market_status.csv` (시장 상태)
  * 내부:

    * 위 데이터들을 모두 merge하여 최종 **랭킹 테이블** 생성
    * 컬럼(실제 `ranking_final.csv`에서 확인되는 것):

      * `date, code,
         pred_return_60d, pred_return_90d,
         pred_mdd_60d, pred_mdd_90d,
         prob_top20_60d, prob_top20_90d,
         score, score_score, composite,
         close, quality_score,
         name, market, sector,
         tech_score, pred_score, ret_score, prob_score, qual_score,
         final_score, risk_penalty,
         market_up,
         market_status_date, market_kospi_close, market_kospi_ma20, market_vol_5d, market_foreign_5d,
         generated_at`
  * 출력:

    * `ranking_final.csv`
  * DB:

    * `daily_ranking` 테이블

      * 스키마는 위 컬럼들과 거의 동일 (추가로 `safety_score`, `liquidity_score`, `model_version` 등 확장용 컬럼 포함)

* **상태**

  * `ranking_final.csv` ↔ `daily_ranking` 테이블 컬럼 구조가 잘 맞고,
  * 점수/예측/시장상태/메타 정보가 한 곳에 다 들어가 있어서

    * **프론트에서 “오늘의 랭킹/추천”을 만들 때는 이 테이블 하나만 보면 됨.**

---

## 6. 트레이드 / 히스토리

* **CSV**: `trades.csv`

  * `trade_id, date, side, code, name, market, sector, qty, price, amount, fee, memo, created_at`
  * 현재 일부 row는 `name, market, sector`가 NaN → DB에서도 nullable로 설계되어 있어서 문제 없음.
* **DB**: `trades` 테이블

  * 동일 스키마, `trade_id` PK (autoincrement)
* **추가**

  * `backtest_trades` 테이블: walkforward/backtest 결과 저장용으로 별도 존재.
  * CSV로는:

    * `backtest_walkforward_*_trades.csv`와 매칭.

---

## 7. 종합 평가 & 이후 업그레이드 팁

### 지금 상태 종합

* **CSV ↔ DB 매칭**

  * `prices_raw / clean / adjusted`, `features`, `labels`, `quality`, `predictions`, `scores_final`, `ranking_final`, `market_status`, `trades`
    → 각각 대응되는 DB 테이블과 **컬럼/타입/PK 구조가 일관되게 맞아 있음**.
* **파이프라인 플로우**

  1. `universe` / `interest_universe` → `universe.csv`
  2. `download_prices_kis` → `prices_daily_raw.csv` + `prices_raw`
  3. `clean_prices` → `prices_daily_clean.csv` + `prices_clean`
  4. `create_adjusted_prices` → `prices_daily_adjusted.csv` + `prices_adjusted`
  5. `fetch_fundamentals_dart` → `fundamentals.csv` + `fundamentals`
  6. `quality_builder` → `quality.csv` + `quality`
  7. `feature_builder` → `features.csv` + `features`
  8. `label_builder` → `labels.csv` + `labels`
  9. `model_train` → `model.pkl`
  10. `model_predict` → `predictions.csv` + `predictions` (+ 히스토리)
  11. `scoring` / 분석 스크립트 → `scores_final.csv` + `daily_scores`
  12. `ranking_builder` → `ranking_final.csv` + `daily_ranking`
* **DB화 관점**

  * “실제 서비스에서 필요할 만한 것들”은 대부분 DB 테이블로 이미 준비되어 있음.
  * 특히 **프론트가 바로 사용할 핵심 테이블**은:

    * `daily_ranking` (최종 추천/점수/시장상태)
    * `predictions` (순수 모델 출력)
    * `features` (인풋 피처)
    * `labels` (백테스트/모델 검증용)
    * `trades` (실제 매매 기록)

### 앞으로 업그레이드할 때 체크리스트

다음 업그레이드(새 피처 추가, 모델 버전업 등) 할 때는 이 정도만 항상 확인하면 돼:

1. **새 컬럼 추가 시**

   * CSV: `features.csv` / `labels.csv` / `predictions.csv` / `ranking_final.csv`에 추가
   * DB: 대응 테이블에 `ALTER TABLE` 또는 CREATE TABLE 재정의 반영
   * `model_train.py`에서 feature/target 분리 로직에 새 컬럼이 잘 분류되는지 확인
2. **모델 버전 변경**

   * `model.pkl` 안의 `pack["features"]` 목록이 `features.csv`와 정확히 같은지
   * `model_predict.py`에서 `Missing feature columns`가 안 나는지
3. **프론트/웹에서 볼 메인 소스**

   * 가능하면 **`daily_ranking` 하나만을 조회**해서 화면 구성
   * 필요하면 `predictions` / `features`를 Drill-down 용도로만 사용
4. **트레이드 연동**

   * 나중에 “내가 실제로 산 종목 vs 모델 추천” 비교하려면

     * `trades` 테이블과 `daily_ranking` / `predictions`를 `date, code`로 조인하면 됨.

---

정리하면,
**지금 시점 기준으로 파이썬 스크립트 ↔ CSV ↔ SQLite DB 구조는 전체적으로 잘 정리된 상태**야.
앞으로는 **새 피처/점수/전략 추가할 때 이 매칭 규칙만 유지**해주면,
프론트 만들 때도 “어디서 뭘 가져와야 할지” 헷갈릴 일이 거의 없을 거야.

이후 업그레이드 계획 세울 때

* “새 피처 추가 버전”
* “새 점수/전략 버전”
  을 나눠서 단계별로 같이 설계해볼까?
